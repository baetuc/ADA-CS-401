{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Task-1.-Compiling-Ebola-Data\"><span class=\"toc-item-num\">Task 1.&nbsp;&nbsp;</span>Compiling Ebola Data</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-2.-RNA-Sequences\"><span class=\"toc-item-num\">Task 2.&nbsp;&nbsp;</span>RNA Sequences</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-3.-Class-War-in-Titanic\"><span class=\"toc-item-num\">Task 3.&nbsp;&nbsp;</span>Class War in Titanic</a></div></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:28.728322Z",
     "start_time": "2017-10-07T23:10:28.726156Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'Data' # Use the data folder provided in Tutorial 02 - Intro to Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Compiling Ebola Data\n",
    "\n",
    "The `DATA_FOLDER/ebola` folder contains summarized reports of Ebola cases from three countries (Guinea, Liberia and Sierra Leone) during the recent outbreak of the disease in West Africa. For each country, there are daily reports that contain various information about the outbreak in several cities in each country.\n",
    "\n",
    "Use pandas to import these data files into a single `Dataframe`.\n",
    "Using this `DataFrame`, calculate for *each country*, the *daily average per month* of *new cases* and *deaths*.\n",
    "Make sure you handle all the different expressions for *new cases* and *deaths* that are used in the reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:28.734009Z",
     "start_time": "2017-10-07T23:10:28.729740Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. RNA Sequences\n",
    "\n",
    "In the `DATA_FOLDER/microbiome` subdirectory, there are 9 spreadsheets of microbiome data that was acquired from high-throughput RNA sequencing procedures, along with a 10<sup>th</sup> file that describes the content of each. \n",
    "\n",
    "Use pandas to import the first 9 spreadsheets into a single `DataFrame`.\n",
    "Then, add the metadata information from the 10<sup>th</sup> spreadsheet as columns in the combined `DataFrame`.\n",
    "Make sure that the final `DataFrame` has a unique index and all the `NaN` values have been replaced by the tag `unknown`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries used\n",
    "\n",
    "Glob library is used in order to leverage regular expression capabilities when reading multiple data with similar name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:28.977576Z",
     "start_time": "2017-10-07T23:10:28.735416Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the spreadsheets into a single `DataFrame`\n",
    "\n",
    "Individual `DataFrames` are read by matching the expression of the file name (*MID#*) and are read into list of dataframes. They are concatenated into a single dataframe `MIDs`.\n",
    "\n",
    "No header exists in the dataset, so the data is read with appropriate function parameters. In order to be able to track the provenance of the data for the metadata, an additional column *Barcode* is added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:29.057268Z",
     "start_time": "2017-10-07T23:10:28.979082Z"
    }
   },
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "\n",
    "# Iterating through all the files satisfying the \"regex\"\n",
    "for file in glob.glob(pathname=DATA_FOLDER+'/microbiome/MID*.xls'):\n",
    "    \n",
    "    # Reading the file\n",
    "    dataframe = pd.read_excel(file, 'Sheet 1', header=None)\n",
    "    \n",
    "    # Defining the barcode attribute so we can track back rows to metadata\n",
    "    dataframe['BARCODE']=os.path.basename(file).split(\".\")[0]\n",
    "\n",
    "    # Giving semantics to columns\n",
    "    dataframe.columns = ['Taxon','Count', 'BARCODE']\n",
    "    dataframe.index.name = 'No.'\n",
    "    \n",
    "    # Appending the read dataframe to the list for later concatenation\n",
    "    dataframes.append(dataframe)\n",
    "\n",
    "# Concatenating dataframes from the list into single dataframe\n",
    "MIDs = pd.concat(dataframes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:29.071968Z",
     "start_time": "2017-10-07T23:10:29.058708Z"
    }
   },
   "outputs": [],
   "source": [
    "MIDs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the DataFrame with metadata\n",
    "\n",
    "Reading the metadata, with *BARCODE* as a natural choice for the key, as it is supposed to be unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:29.081026Z",
     "start_time": "2017-10-07T23:10:29.073351Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_excel(DATA_FOLDER+'/microbiome/metadata.xls', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:29.089988Z",
     "start_time": "2017-10-07T23:10:29.082485Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing left join on MIDs DataFrame to make a connection with metadata DataFrame. The join is performed on the *BARCODE* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:29.107386Z",
     "start_time": "2017-10-07T23:10:29.091367Z"
    }
   },
   "outputs": [],
   "source": [
    "finalDF = MIDs.join(metadata, on='BARCODE')\n",
    "finalDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index uniqueness\n",
    "\n",
    "Let us assert if the existing choice to index on the occurence when reading the separate data file results in an unique index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:29.112309Z",
     "start_time": "2017-10-07T23:10:29.108899Z"
    }
   },
   "outputs": [],
   "source": [
    "finalDF.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It could have been guessed that for uniqueness number of row of each file would not be appropriate, since we have concatenated several such files. Another strategy would be to add additional information unique to the each file, such as *BARCODE*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:29.122636Z",
     "start_time": "2017-10-07T23:10:29.114432Z"
    }
   },
   "outputs": [],
   "source": [
    "finalDF_unique = finalDF.copy()\n",
    "finalDF_unique.index = finalDF.index.astype(str) + ' ' + finalDF.BARCODE\n",
    "finalDF_unique.index.name = 'id'\n",
    "\n",
    "finalDF_unique.index.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:29.134109Z",
     "start_time": "2017-10-07T23:10:29.124500Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "finalDF_unique.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark on index uniqueness\n",
    "\n",
    "Different approaches could be taken in unique index selection. One of the options could have been to use *Taxon* as a primary index. It would still result in a non-unique index when different files are combined in a single DataFrame since same taxons are present in different measurements. On the same note, concatenating the *BARCODE* value would result in an unique index.k\n",
    "\n",
    "With current approach the row identifier length is kept small (6 characters), while with the aforementioned option such size would both vary and be significantly larger, potentially impacting performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:29.149784Z",
     "start_time": "2017-10-07T23:10:29.136035Z"
    }
   },
   "outputs": [],
   "source": [
    "finalDF_unique_h1 = finalDF.copy()\n",
    "finalDF_unique_h1 = finalDF_unique_h1.set_index([\"Taxon\",\"BARCODE\"])\n",
    "\n",
    "finalDF_unique_h1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:29.155465Z",
     "start_time": "2017-10-07T23:10:29.151112Z"
    }
   },
   "outputs": [],
   "source": [
    "finalDF_unique_h1.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option which would bring more semantic and group the data would be to perform hierarchical indexing, based on *BARCODE* as level 0, and *Taxon* as level 1 index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:29.183819Z",
     "start_time": "2017-10-07T23:10:29.157228Z"
    }
   },
   "outputs": [],
   "source": [
    "finalDF_unique_h2 = finalDF.copy()\n",
    "finalDF_unique_h2 = finalDF_unique_h2.set_index([\"BARCODE\",\"Taxon\"])\n",
    "\n",
    "finalDF_unique_h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:29.188799Z",
     "start_time": "2017-10-07T23:10:29.185306Z"
    }
   },
   "outputs": [],
   "source": [
    "finalDF_unique_h2.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, handling NaN values\n",
    "\n",
    "For this purpose we will use `finalDF_unique` DataFrame, but the logic remains the same whichever type of indexing we pick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:29.201147Z",
     "start_time": "2017-10-07T23:10:29.190324Z"
    }
   },
   "outputs": [],
   "source": [
    "finalDF_unique.fillna('unknown', inplace=True)\n",
    "\n",
    "finalDF_unique.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Class War in Titanic\n",
    "\n",
    "Use pandas to import the data file `Data/titanic.xls`. It contains data on all the passengers that travelled on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:29.206004Z",
     "start_time": "2017-10-07T23:10:29.202456Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(filename=DATA_FOLDER+'/titanic.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the following questions state clearly your assumptions and discuss your findings:\n",
    "1. Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. \n",
    "2. Plot histograms for the *travel class*, *embarkation port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. \n",
    "3. Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "4. For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*.\n",
    "5. Calculate the proportion of the passengers that survived by *travel class* and *sex*. Present your results in *a single histogram*.\n",
    "6. Create 2 equally populated *age categories* and calculate survival proportions by *age category*, *travel class* and *sex*. Present your results in a `DataFrame` with unique index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:29.301726Z",
     "start_time": "2017-10-07T23:10:29.207300Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:29.369983Z",
     "start_time": "2017-10-07T23:10:29.303215Z"
    }
   },
   "outputs": [],
   "source": [
    "# loading data from the xls file\n",
    "titanic_data = pd.read_excel(DATA_FOLDER+'/titanic.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type and value range\n",
    "\n",
    "We use **dtypes** parameter of the DataFrame in which we loaded the xls to describe the types of the attributes\n",
    "\n",
    "We use the **describe()** method for the value range with the following assumptions:\n",
    "\n",
    ">if the describe() method returns a Series that has a *min* and a *max* entry we use those limits as a range\n",
    "\n",
    ">otherwise\n",
    "\n",
    ">if the describe() method returns a Series that has an *unique* entry then we assume that the type of the attribute is not a number but rather an object so mapping all the unique entries to an integer id starting from one, we can have a range from 1 -> # of unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:29.375580Z",
     "start_time": "2017-10-07T23:10:29.371358Z"
    }
   },
   "outputs": [],
   "source": [
    "# dtypes parameter returns information regarding the type of each Series in a DataFrame\n",
    "titanic_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:29.419888Z",
     "start_time": "2017-10-07T23:10:29.376851Z"
    }
   },
   "outputs": [],
   "source": [
    "# variables we use to collect the min and max values for each attribute\n",
    "min_ranges = []\n",
    "max_ranges = []\n",
    "for c in titanic_data.columns:\n",
    "    # obtain the description of current column\n",
    "    column_description = titanic_data[c].describe()\n",
    "    if 'min' in column_description and 'max' in column_description: \n",
    "        min_ranges.append(column_description['min'])\n",
    "        max_ranges.append(column_description['max'])\n",
    "    elif 'unique' in column_description:\n",
    "        min_ranges.append('1')\n",
    "        max_ranges.append(column_description['unique'])\n",
    "        \n",
    "# we put the data obtained into a DataFrame indexed by the column names\n",
    "# which is automatically indexed by the column names given that \n",
    "# titanic_data.dtypes returns a series\n",
    "df = pd.DataFrame({\n",
    "    'type':titanic_data.dtypes,\n",
    "    'min range':min_ranges,\n",
    "    'max range':max_ranges,\n",
    "})[['type', 'min range', 'max range']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical data\n",
    "\n",
    "**pclass** column represents the three travel classes and can be a nominal categorical variable. Even though the data in this column already has type int64 and the set of values (1,2,3). The number of possible values is much smaller than the number of data entries so according to the docs, it will use less space. Indeed, after some testing, the number of bytes post conversion is smaller than pre. Therefore it would make sense (space, eficiency, and semantically wise) to convert it to categorical\n",
    "\n",
    "**sex** column is populated for every data entry in the dataset with either \"male\"/\"female\". In this case, comparing to the one above, there is an even better improvement regarding the space if we convert the column to categorical.\n",
    "\n",
    "**survived** column has values 1 and 0 so it makes sense to be nominal categorical variable\n",
    "\n",
    "**embarked** column denotes one of the three ports of embarkation S, C and Q (here we assume that these are all the ports of embarkation because there are 2 missing values) so it can be a nominal categorical variable\n",
    "\n",
    "**sibsp** column represents the number of siblings/spouses a passenger had on board. It takes values in the set {0,1,2,3,4,5,8} but this set is not well defined therefore we choose not to consider it categorical.\n",
    "\n",
    "**cabin** column has a rather small number of unique values 186/295 so semantically cannot be said it fully represents a category. The set being rather small, we choose not to consider it categorical\n",
    "\n",
    "**boat** column with 28/486 unique values can definitely be considered a nominal categorical variable \n",
    "\n",
    "**home.dest** column contains string representations of multiple cities, states and countries, common to multiple passengers. Casting it to categorical is not only a reasonable idea but also an effiency improvement  \n",
    "\n",
    "We assumed that the **ticket column** representing the ticket number is individual, even though the number of unique values is smaller than the number of passengers, therefore it does not make sense to be a category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:29.427761Z",
     "start_time": "2017-10-07T23:10:29.421175Z"
    }
   },
   "outputs": [],
   "source": [
    "# testing the memory used by a Series with a values set of (1,2,3) before and after casting to category\n",
    "print('Number of unique values:', len(titanic_data.pclass.value_counts()))\n",
    "print('Type of data:', titanic_data.pclass.dtype)\n",
    "print('Nr of bytes before cast:', titanic_data.pclass.nbytes)\n",
    "print('Nr of bytes after  cast:', titanic_data.pclass.astype('category').nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:29.436728Z",
     "start_time": "2017-10-07T23:10:29.429135Z"
    }
   },
   "outputs": [],
   "source": [
    "#categorical_columns = ['pclass', 'sex', 'survived', 'embarked', 'boat', 'home.dest']\n",
    "categorical_columns = ['pclass', 'sex', 'embarked', 'boat', 'home.dest']\n",
    "for cat_col in categorical_columns:\n",
    "    titanic_data[cat_col] = titanic_data[cat_col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:29.444598Z",
     "start_time": "2017-10-07T23:10:29.438258Z"
    }
   },
   "outputs": [],
   "source": [
    "titanic_data['boat'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Histograms -> would it make more sense for the values to be normalized?\n",
    "\n",
    "Plot histograms for the *travel class*, *embarkation port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:29.687586Z",
     "start_time": "2017-10-07T23:10:29.446456Z"
    }
   },
   "outputs": [],
   "source": [
    "# libraries used for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:29.696076Z",
     "start_time": "2017-10-07T23:10:29.689155Z"
    }
   },
   "outputs": [],
   "source": [
    "''' \n",
    "Function that makes it easy to create a bar plot\n",
    "\n",
    "Takes a Series as data \n",
    "'''\n",
    "def bar_plot(data, title, labels_rotation_angle=0):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(title + ' bar plot', fontsize=15, fontweight='bold')\n",
    "    sns.barplot(data.keys(), data, ax=ax)\n",
    "    locs, labels = plt.xticks()\n",
    "    plt.setp(labels, rotation=labels_rotation_angle)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Travel class bar plot \n",
    "\n",
    "For the travel class it makes sense to use a bar plot for visualization because the data has a discrete value set of {1,2,3} therefore we do not accumulate the values over some intervals so that a histogram to be necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:29.865512Z",
     "start_time": "2017-10-07T23:10:29.697500Z"
    }
   },
   "outputs": [],
   "source": [
    "travel_class_counts = titanic_data.pclass.value_counts().sort_index()\n",
    "travel_class_counts.index = ['First class', 'Second class', 'Third class']\n",
    "bar_plot(travel_class_counts, 'Travel class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:30.020713Z",
     "start_time": "2017-10-07T23:10:29.866950Z"
    }
   },
   "outputs": [],
   "source": [
    "# seaborn one-liner\n",
    "sns.factorplot(x='pclass', data=titanic_data, kind='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embarkation point bar plot \n",
    "\n",
    "For the embarkation point it makes sense to use again a bar plot because of the same reason as for the travel class, only here the values set is {S, C, Q}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:30.155185Z",
     "start_time": "2017-10-07T23:10:30.022071Z"
    }
   },
   "outputs": [],
   "source": [
    "embarkation_port_counts = titanic_data.embarked.value_counts().sort_index()\n",
    "embarkation_port_counts.index = [\"Cherbourg\", \"Queenstown\", \"Southampton\"]\n",
    "bar_plot(embarkation_port_counts, 'Embarkation point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:30.160072Z",
     "start_time": "2017-10-07T23:10:30.156583Z"
    }
   },
   "outputs": [],
   "source": [
    "titanic_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:30.317879Z",
     "start_time": "2017-10-07T23:10:30.161972Z"
    }
   },
   "outputs": [],
   "source": [
    "# seaborn one-liner\n",
    "sns.factorplot(x='embarked', data=titanic_data, kind='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passengers sex bar plot\n",
    "\n",
    "For the passengers sex is reasonable as well to us a bar plot given that we have only two discrete values {female, male}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:30.461283Z",
     "start_time": "2017-10-07T23:10:30.319948Z"
    }
   },
   "outputs": [],
   "source": [
    "passengers_sex_counts = titanic_data.sex.value_counts()\n",
    "bar_plot(passengers_sex_counts, 'Passenger sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:30.624111Z",
     "start_time": "2017-10-07T23:10:30.463236Z"
    }
   },
   "outputs": [],
   "source": [
    "# seaborn one-liner\n",
    "sns.factorplot('sex', data=titanic_data, kind='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passengers age histogram  ---- !!**Must make assumptions for the age < 0**\n",
    "\n",
    "Given that we want to visualize the age in discrete decade intervals, meaning that multiple values will vote for the same bar, we will use a histogram. \n",
    "\n",
    "\n",
    "For this attribute we ignore the NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:30.631929Z",
     "start_time": "2017-10-07T23:10:30.625494Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Funciton to easily plot a histogram\n",
    "Expects a Pandas Series and an array corresponding to the margins of the bins \n",
    "'''\n",
    "def histogram_plot(data, bins,title=\"\"):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(title + ' histogram', fontsize=15, fontweight='bold')\n",
    "    plt.hist(data, bins)\n",
    "    plt.xlabel('age')\n",
    "    plt.ylabel('# of passengers')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:30.805018Z",
     "start_time": "2017-10-07T23:10:30.633254Z"
    }
   },
   "outputs": [],
   "source": [
    "# first approach -> using histogram built-in functions and specifying the bins\n",
    "passengers_age = titanic_data.age[pd.notnull(titanic_data.age)]\n",
    "histogram_plot(passengers_age, bins=[0,10,20,30,40,50,60,70,80,90], title='Passengers age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:31.056485Z",
     "start_time": "2017-10-07T23:10:30.806362Z"
    }
   },
   "outputs": [],
   "source": [
    "# second approach -> discretization of data using pandas cut function\n",
    "age_by_decade = pd.cut(passengers_age, [0, 10, 20, 30, 40, 50, 60, 70, 80, 90], right=False).value_counts()\n",
    "bar_plot(age_by_decade, 'Age by decade', labels_rotation_angle=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 \n",
    "Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "\n",
    "In order to do this, we must first determine the number of passengers per cabin floor. This number is not accurate with respect to reality given that not every passenger's data entry contains information about the cabin floor.\n",
    "\n",
    "We assume that the decks were index by letters {A, B, C, D, E, F, G} https://www.encyclopedia-titanica.org/titanic-deckplans/.\n",
    "We assume that the first character in the cabin column corresponds to the cabin's deck.\n",
    "\n",
    "Cases that we take care of:\n",
    ">Passengers with multiple cabins. Solution: we observe that the same multiple-cabins values correspond to multiple passengers. Given that we are interested in number of passengers per floor, we simply add one to the corresponding floor for each of them. The only problem could be that a passenger has cabins on multiple floors. So we check for these cases and find that there are not. Deck F has multiple sections with different identification letters as described lower so we do not consider them multiple floors.\n",
    ">\n",
    ">Cabin data with value T. Solution: we consider these values wrong and replace them with np.nan because T does not correspond to any deck as can be seen in https://www.encyclopedia-titanica.org/titanic-deckplans/\n",
    ">\n",
    ">Cabin data with values that start with F correspond to the F-Deck which has several sections (as can be seen in the F-deck plan https://www.encyclopedia-titanica.org/titanic-deckplans/f-deck.html) like R, G, E, C, J, H, hence the values like \"F G63\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:31.070923Z",
     "start_time": "2017-10-07T23:10:31.057888Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_multiple_floors(cabin_entry):\n",
    "    cabins = cabin_entry.split(' ')\n",
    "    # extract the deck letter\n",
    "    for i in range(len(cabins)):\n",
    "        cabins[i] = cabins[i][0]\n",
    "    # verify if all values are equal\n",
    "    return not(cabins[1:] == cabins[:-1])\n",
    "\n",
    "for cabin_entry in titanic_data.cabin:\n",
    "    if cabin_entry is not np.nan and (check_multiple_floors(cabin_entry)):\n",
    "        if cabin_entry.startswith('F'):\n",
    "            print(\"This format specifies a section of the F-deck:\", cabin_entry)\n",
    "        else:\n",
    "            print(cabin_entry, ' has cabins on multiple floors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:31.077603Z",
     "start_time": "2017-10-07T23:10:31.072353Z"
    }
   },
   "outputs": [],
   "source": [
    "# replace T values with np.nan\n",
    "titanic_data['cabin'] = titanic_data.cabin.map(lambda cabin: np.nan if cabin == 'T' else cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:31.085510Z",
     "start_time": "2017-10-07T23:10:31.078963Z"
    }
   },
   "outputs": [],
   "source": [
    "# get a look at the values on F-deck\n",
    "titanic_data[titanic_data.cabin.str[0] == 'F'].cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:31.091649Z",
     "start_time": "2017-10-07T23:10:31.086852Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "'''\n",
    "Simple function to make it ease to create pie charts\n",
    "data: array-like\n",
    "labels: list\n",
    "'''\n",
    "def pie_chart(data, labels, title, start_angle, colours=None):\n",
    "    plt.pie(data, labels=labels, autopct='%1.1f%%', startangle=start_angle, )\n",
    "    plt.title(title, fontsize=15, fontweight='bold')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:31.214864Z",
     "start_time": "2017-10-07T23:10:31.093093Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cabins_per_floor = titanic_data.cabin.str[0].value_counts().sort_index()\n",
    "\n",
    "piechart_title = \"Proportions of passengers by cabin floor\"\n",
    "pie_chart(cabins_per_floor.values, cabins_per_floor.index, piechart_title, 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Survival proportions by travel class\n",
    "\n",
    "For each travel class, calculate the proportion of the passengers that survived. Present your results in pie charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:31.220242Z",
     "start_time": "2017-10-07T23:10:31.216333Z"
    }
   },
   "outputs": [],
   "source": [
    "# check if we have survival data for all passengers\n",
    "titanic_data.survived.notnull().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:31.520228Z",
     "start_time": "2017-10-07T23:10:31.221767Z"
    }
   },
   "outputs": [],
   "source": [
    "class_statistics = titanic_data.groupby(titanic_data.pclass)['survived'].agg(['sum', 'count'])\n",
    "class_statistics['count'] = class_statistics['count'] - class_statistics['sum']\n",
    "class_statistics.columns = ['survived', 'did_not_survive']\n",
    "for i in range(len(class_statistics)):\n",
    "    pie_chart(class_statistics.iloc[i], class_statistics.columns, 'Proportion of surviving passengers for class {}'.format(i+1), 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Survival proportions by class and sex\n",
    "Calculate the proportion of the passengers that survived by travel class and sex. Present your results in a single histogram.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:31.528261Z",
     "start_time": "2017-10-07T23:10:31.521627Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate the proportions grouping the date by class and sex, then aggregating over survived column\n",
    "# using sum to get the number of surviving passengers and count to get the total number of passengers\n",
    "class_sex_statistics = titanic_data.groupby(['pclass', 'sex'])['survived'].agg(['sum', 'count'])\n",
    "class_sex_statistics.columns = ['survived', 'count']\n",
    "class_sex_statistics['survival_rate'] = class_sex_statistics['survived']/class_sex_statistics['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:31.533568Z",
     "start_time": "2017-10-07T23:10:31.529509Z"
    }
   },
   "outputs": [],
   "source": [
    "statistics_reindexed = class_sex_statistics.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:31.785501Z",
     "start_time": "2017-10-07T23:10:31.534848Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.factorplot(x='pclass', y='survival_rate', hue='sex',\n",
    "               data=statistics_reindexed, kind='bar', size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:32.164382Z",
     "start_time": "2017-10-07T23:10:31.786924Z"
    }
   },
   "outputs": [],
   "source": [
    "#seaborn one-liner\n",
    "sns.factorplot(x=\"pclass\", y=\"survived\", hue=\"sex\", data=titanic_data,\n",
    "               size=6,kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age categories\n",
    "Create 2 equally populated age categories and calculate survival proportions by age category, travel class and sex. Present your results in a DataFrame with unique index.\n",
    "\n",
    "\n",
    "\n",
    ">For this task it was decided that the NaN values of the attribute age to be excluded.\n",
    "\n",
    "To divide the data in two age categories we choose to use the **qcut** method because it creates two meaningful categories (<= 28 and >28) with the number of values as close as possible. We could have splitted the data ourselves in two equally populated age categories but we would loose their meaningfulness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:32.170531Z",
     "start_time": "2017-10-07T23:10:32.165715Z"
    }
   },
   "outputs": [],
   "source": [
    "titanic_clean_age = titanic_data[pd.notnull(titanic_data.age)].copy()\n",
    "titanic_clean_age.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:32.177445Z",
     "start_time": "2017-10-07T23:10:32.171760Z"
    }
   },
   "outputs": [],
   "source": [
    "categ = pd.qcut(titanic_clean_age.age, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:32.182578Z",
     "start_time": "2017-10-07T23:10:32.178660Z"
    }
   },
   "outputs": [],
   "source": [
    "titanic_clean_age['age_cat'] = categ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:32.191283Z",
     "start_time": "2017-10-07T23:10:32.183816Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_stats = titanic_clean_age.groupby(['age_cat', 'pclass', 'sex'])['survived'].agg(['sum','count'])\n",
    "cat_stats.columns=['survived', 'total']\n",
    "cat_stats['proportions'] = cat_stats['survived']/cat_stats['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:32.203067Z",
     "start_time": "2017-10-07T23:10:32.192798Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T23:10:32.207626Z",
     "start_time": "2017-10-07T23:10:32.204410Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_stats.index.is_unique"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada]",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
